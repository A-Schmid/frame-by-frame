{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mif_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nGZoEX8iAfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b52bdce8-ec35-4e17-fa9c-2f2733ec665a"
      },
      "source": [
        "# Install decord if necessary\n",
        "!pip install --upgrade decord"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting decord\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/5e/e2be6a3a3a46275059574d9c6a1d422aa6c7c3cbf6614939b8a3c3f8f2d5/decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1MB 250kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from decord) (1.19.5)\n",
            "Installing collected packages: decord\n",
            "Successfully installed decord-0.5.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "source": [
        "Load pretrained model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzscOB3DeenY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b828f5-b9b0-4c7b-8927-8e3a9c62deb5"
      },
      "source": [
        "#%% Define and load model\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "with_cuda = False\n",
        "# Define and load model\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "with_cuda = False\n",
        "path_prefix = Path('..')\n",
        "\n",
        "if with_cuda:\n",
        "    resnet50 = models.resnet50(pretrained=False, progress=True, num_classes=339).to('cuda')\n",
        "else:\n",
        "    resnet50 = models.resnet50(pretrained=False, progress=True, num_classes=339)\n",
        "\n",
        "# Load pretrained weights (MiTv1)\n",
        "#path_model = Path('/content/drive/MyDrive/resnet50_moments-fd0c4436.pth')\n",
        "path_model = path_prefix / 'models/resnet50_moments-fd0c4436.pth'\n",
        "resnet50.load_state_dict(torch.load(path_model))\n",
        "\n",
        "# Evaluation mode\n",
        "resnet50.eval()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=339, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "source": [
        "Define transformations"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8neHBNYeyIG"
      },
      "source": [
        "#%% Transformations\n",
        "import torchvision.transforms as transforms\n",
        "transformation = transforms.Compose([\n",
        "                                     transforms.ToPILImage(mode='RGB'), # required if the input image is a nd.array\n",
        "                                     transforms.Resize(224), # To be changed to rescale to keep the aspect ration?\n",
        "                                     transforms.CenterCrop((224, 224)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                          std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "source": [
        "Load categories"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgpkWhHQe2Zk"
      },
      "source": [
        "# %% Load categories\n",
        "\n",
        "path_labels = path_prefix / 'labels/category_momentsv1.txt'\n",
        "\n",
        "def load_categories():\n",
        "    \"\"\"Load categories.\"\"\"\n",
        "    with open(path_labels) as f:\n",
        "        return [line.rstrip() for line in f.readlines()]\n",
        "\n",
        "# load categories\n",
        "categories = load_categories()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Load videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3rEchfte5wa",
        "outputId": "6fffc65a-4dcc-4ca3-8e0a-748ced6da42f"
      },
      "source": [
        "#%% Sweep through files in subfolders of path_input\n",
        "import os\n",
        "path_input = path_prefix / 'data/MIT_sampleVideos_RAW_final'\n",
        "\n",
        "l_videos = []\n",
        "for path, subdirs, files in os.walk(path_input):\n",
        "  for name in files:\n",
        "    if name[-3:] == 'mp4':\n",
        "      l_videos.append([path.split('/')[-1],   # category\n",
        "                       name])                 # file name\n",
        "    else:\n",
        "      print('Ignored: ', name)\n",
        "\n",
        "if l_videos:\n",
        "  l_videos = sorted(l_videos)\n",
        "print('Total nr. of MP4s: ', len(l_videos))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignored:  .DS_Store\nTotal nr. of MP4s:  1544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['aiming', 'yt-0gwUV4Ze-Hs_390.mp4'], ['aiming', 'yt-0qYbATyHm2A_59.mp4'], ['aiming', 'yt-2yYb3iQCivw_130.mp4'], ['aiming', 'yt-chT_6aIyhD4_47.mp4'], ['aiming', 'yt-fG9wZzs4jis_124.mp4'], ['aiming', 'yt-fM2iXUuaP7U_48.mp4'], ['aiming', 'yt-iVSy96zolvw_23.mp4'], ['applauding', 'yt-06tUmXhgnSY_4.mp4'], ['applauding', 'yt-A70byjNkwdA_4.mp4'], ['applauding', 'yt-E14-2TmbCD8_12.mp4']]\n"
          ]
        }
      ],
      "source": [
        "print(l_videos[:10])"
      ]
    },
    {
      "source": [
        "Extract prediction accuracies on MIFs (most informative frame, i.e. frame w/ highest prediction accuracy)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTF7ta-Ge9qL",
        "outputId": "32d09d66-63fe-4c08-f020-0f665686efdb"
      },
      "source": [
        "# %% Sweep through videos\n",
        "import time\n",
        "import decord\n",
        "decord.bridge.set_bridge('native') # Seems to be the fastest option\n",
        "from decord import cpu, gpu\n",
        "from decord import VideoReader\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "l_mifs = []\n",
        "\n",
        "# Iterate over entries in l_videos:\n",
        "for j in range(len(l_videos[:10])):\n",
        "  # Verbose\n",
        "  if j%50 == 0:\n",
        "    print(f'{j}/{len(l_videos)}')\n",
        "  \n",
        "  \n",
        "  # Define path\n",
        "  category, file_name = l_videos[j]\n",
        "  cat_idx = categories.index(category)\n",
        "  path_input_file = str(path_input / category/ file_name)\n",
        "  \n",
        "  \n",
        "  # Load video with Decord.VideoReader\n",
        "  vr = VideoReader(path_input_file)\n",
        "  video_frames = vr.get_batch(range(0, len(vr), 1)).asnumpy()\n",
        "  \n",
        "  # Define empty array for accuracies\n",
        "  pred_accuracies = np.zeros((video_frames.shape[0], ))\n",
        "\n",
        "  # Iterate over frames\n",
        "  for i in range(video_frames.shape[0]):\n",
        "    if with_cuda:\n",
        "      input = transformation(video_frames[i]).to('cuda')\n",
        "    else:\n",
        "      input = transformation(video_frames[i])\n",
        "    \n",
        "    # Classification:\n",
        "    logit = resnet50.forward(input.unsqueeze(0))      # extract output to given input \n",
        "    h_x = F.softmax(logit, 1).data.squeeze()[cat_idx] # transform to softmax\n",
        "    pred_accuracies[i]= h_x\n",
        "\n",
        "  \n",
        "  # Append to output list\n",
        "  l_mifs.append([category, file_name,\n",
        "                 np.argmax(pred_accuracies),\n",
        "                 pred_accuracies[np.argmax(pred_accuracies)]])\n",
        "   \n",
        "stop = time.time()\n",
        "duration = stop-start\n",
        "print(f'\\nTime elapsed:: {duration:.4f}s (~ {duration/j:.2f}s per file)')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/1544\n",
            "\n",
            "Time elapsed:: 199.2183s (~ 22.14s per file)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8faa9a8V1w6v"
      },
      "source": [
        "Stack together and save to csv as: \\\\\n",
        "  `category, fname, mif_idx`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soWUKoct99Yd",
        "outputId": "33037a38-b7e8-4975-d644-566eae80c067"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(l_mifs, columns=['category', 'fname', 'mif_idx', 'softmax[category]'])\n",
        "print(df)\n",
        "df.to_csv(path_prefix / 'saved/mifs.csv')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     category                   fname  mif_idx  softmax[category]\n0      aiming  yt-0gwUV4Ze-Hs_390.mp4       58           0.607241\n1      aiming   yt-0qYbATyHm2A_59.mp4        4           0.068653\n2      aiming  yt-2yYb3iQCivw_130.mp4       41           0.407697\n3      aiming   yt-chT_6aIyhD4_47.mp4        8           0.019289\n4      aiming  yt-fG9wZzs4jis_124.mp4        1           0.354655\n5      aiming   yt-fM2iXUuaP7U_48.mp4        0           0.051184\n6      aiming   yt-iVSy96zolvw_23.mp4       43           0.270948\n7  applauding    yt-06tUmXhgnSY_4.mp4       48           0.062576\n8  applauding    yt-A70byjNkwdA_4.mp4        0           0.026515\n9  applauding   yt-E14-2TmbCD8_12.mp4        1           0.540867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTsOB6_wfD6-"
      },
      "source": [
        "TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhKjMSWJfDaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a319fd9a-289c-4bfa-fbe2-902c3f8579e9"
      },
      "source": [
        "from pathlib import Path\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "dict_path = path_prefix / 'saved/ResNet50_MiTv1_accuracies_per_category.pkl'\n",
        "# Load from file\n",
        "f = open(dict_path, 'rb')\n",
        "accuracies_per_category = pickle.load(f)\n",
        "\n",
        "l_categories = categories\n",
        "\n",
        "category_name = 'aiming'\n",
        "video_fname = 'yt-0gwUV4Ze-Hs_390.mp4'\n",
        "\n",
        "per_frame_accuracies = np.array(accuracies_per_category[category_name][video_fname])\n",
        "\n",
        "print(f'\\t{video_fname} : Max/Min accuracy at frame:' \\\n",
        "f' {np.argmax(per_frame_accuracies)}/{np.argmin(per_frame_accuracies)}' \\\n",
        "f' with value: {per_frame_accuracies[np.argmax(per_frame_accuracies)]}' \\\n",
        "f' / {per_frame_accuracies[np.argmin(per_frame_accuracies)]}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tyt-0gwUV4Ze-Hs_390.mp4 : Max/Min accuracy at frame: 58/23 with value: [0.60724086] / [0.083207]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  category                   fname  mif_idx  softmax[category]\n",
              "0   aiming  yt-0gwUV4Ze-Hs_390.mp4       58           0.607241"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>fname</th>\n      <th>mif_idx</th>\n      <th>softmax[category]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aiming</td>\n      <td>yt-0gwUV4Ze-Hs_390.mp4</td>\n      <td>58</td>\n      <td>0.607241</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df.loc[lambda df: df['fname'] == video_fname]"
      ]
    }
  ]
}