{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mif_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VywOTfzNhGVd"
      },
      "source": [
        "Install decord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nGZoEX8iAfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "35dca952-5b00-47a6-9814-5f35f9b9e896"
      },
      "source": [
        "!pip install --upgrade decord"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting decord\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/5e/e2be6a3a3a46275059574d9c6a1d422aa6c7c3cbf6614939b8a3c3f8f2d5/decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1MB 245kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from decord) (1.19.5)\n",
            "Installing collected packages: decord\n",
            "Successfully installed decord-0.5.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzscOB3DeenY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe46996-b3f3-44b1-904c-30208415bbab"
      },
      "source": [
        "#%% Define and load model\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define\n",
        "resnet50 = models.resnet50(pretrained=False, progress=True, num_classes=339).to('cuda')\n",
        "# Load pretrained weights (MiTv1)\n",
        "path_model = Path('/content/drive/MyDrive/resnet50_moments-fd0c4436.pth')\n",
        "resnet50.load_state_dict(torch.load(path_model))\n",
        "# Evaluation mode\n",
        "resnet50.eval()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=339, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8neHBNYeyIG"
      },
      "source": [
        "#%% Transformations\n",
        "import torchvision.transforms as transforms\n",
        "transformation = transforms.Compose([\n",
        "                                     transforms.ToPILImage(mode='RGB'), # required if the input image is a nd.array\n",
        "                                     transforms.Resize(224), # To be changed to rescale to keep the aspect ration?\n",
        "                                     transforms.CenterCrop((224, 224)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                          std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgpkWhHQe2Zk"
      },
      "source": [
        "# %% Load categories\n",
        "def load_categories():\n",
        "    \"\"\"Load categories.\"\"\"\n",
        "    with open(Path('/content/drive/MyDrive/category_momentsv1.txt')) as f:\n",
        "        return [line.rstrip() for line in f.readlines()]\n",
        "\n",
        "# load categories\n",
        "categories = load_categories()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3rEchfte5wa",
        "outputId": "b0526f30-d373-490f-888e-f3069fa43e17"
      },
      "source": [
        "#%% Sweep through files in subfolders of path_input\n",
        "import os\n",
        "path_input = Path('/content/drive/MyDrive/MIT_sampleVideos_RAW_final_25FPS').absolute()\n",
        "\n",
        "l_videos = []\n",
        "for path, subdirs, files in os.walk(path_input):\n",
        "  for name in files:\n",
        "    if name[-3:] == 'mp4':\n",
        "      l_videos.append([path.split('/')[-1],   # category\n",
        "                       name])                 # file name\n",
        "    else:\n",
        "      print('Ignored: ', name)\n",
        "\n",
        "if l_videos:\n",
        "  l_videos = sorted(l_videos)\n",
        "print('Total nr. of MP4s: ', len(l_videos))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ignored:  readme.txt\n",
            "Ignored:  .DS_Store\n",
            "Total nr. of MP4s:  1458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3XkGu8_y047",
        "outputId": "0d2a78c5-faf3-4005-abf6-bedc21f2134a"
      },
      "source": [
        "np.array(l_videos)[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['balancing', 'yt-m3zrcNknWVE_253.mp4'], dtype='<U131')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTF7ta-Ge9qL",
        "outputId": "f5d65ec3-6319-4803-dcac-6d874b59f80b"
      },
      "source": [
        "# %% Sweep through videos\n",
        "import time\n",
        "import decord\n",
        "decord.bridge.set_bridge('native') # Seems to be the fastest option\n",
        "from decord import cpu, gpu\n",
        "from decord import VideoReader\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "vervbose = True\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "#arr_mifs = np.empty(len(l_videos), dtype=np.int8)\n",
        "l_mifs = []\n",
        "\n",
        "for j in range(len(l_videos)):\n",
        "  category, file_name = l_videos[j]\n",
        "  # Verbose\n",
        "  if j%50 == 0:\n",
        "    print(f'{j}/{len(l_videos)}')\n",
        "\n",
        "  cat_idx = categories.index(category)\n",
        "  path_input_file = str(path_input / category/ file_name)\n",
        "  \n",
        "  # Load video with Decord.VideoReader\n",
        "  vr = VideoReader(path_input_file)\n",
        "  video_frames = vr.get_batch(range(0, len(vr), 1)).asnumpy()\n",
        "  \n",
        "  #pred_accuracies = torch.zeros((video_frames.shape[0], ))\n",
        "  pred_accuracies = np.zeros((video_frames.shape[0], ))\n",
        "\n",
        "  for i in range(video_frames.shape[0]):\n",
        "    input = transformation(video_frames[i]).to('cuda')\n",
        "    \n",
        "    # Classification:\n",
        "    logit = resnet50.forward(input.unsqueeze(0))\n",
        "    #h_x = F.softmax(logit, 1).data.squeeze().tolist()\n",
        "    h_x = F.softmax(logit, 1).data.squeeze()[cat_idx]\n",
        "    pred_accuracies[i]= h_x\n",
        "\n",
        "  #arr_mifs[j] = np.argmax(pred_accuracies)\n",
        "\n",
        "  l_mifs.append([category, file_name,\n",
        "                 np.argmax(pred_accuracies),\n",
        "                 pred_accuracies[np.argmax(pred_accuracies)]])\n",
        "  \n",
        "#print(np.argmax(pred_accuracies), pred_accuracies[np.argmax(pred_accuracies)])\n",
        "    \n",
        "stop = time.time()\n",
        "duration = stop-start\n",
        "print(f'\\nTime spent: {duration:.4f}s (~ {duration/j:.2f}s per file)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0/1458\n",
            "50/1458\n",
            "100/1458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8faa9a8V1w6v"
      },
      "source": [
        "Stack together and save to csv as: \\\\\n",
        "  `category, fname, mif_idx`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soWUKoct99Yd",
        "outputId": "69a15592-7cd7-4979-89bb-6b5cf9800e63"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(l_mifs, columns=['category', 'fname', 'mif_idx', 'softmax[category]'])\n",
        "print(df)\n",
        "df.to_csv('/content/drive/MyDrive/MIT_sampleVideos_RAW_final_25FPS/mifs.csv')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     category                   fname  mif_idx  softmax[category]\n",
            "0      aiming  yt-0gwUV4Ze-Hs_390.mp4       50           0.627705\n",
            "1      aiming   yt-0qYbATyHm2A_59.mp4        2           0.055494\n",
            "2      aiming  yt-2yYb3iQCivw_130.mp4       36           0.409956\n",
            "3      aiming   yt-chT_6aIyhD4_47.mp4        6           0.021016\n",
            "4      aiming  yt-fG9wZzs4jis_124.mp4        1           0.331710\n",
            "5      aiming   yt-fM2iXUuaP7U_48.mp4        0           0.050344\n",
            "6      aiming   yt-iVSy96zolvw_23.mp4       37           0.208761\n",
            "7  applauding    yt-06tUmXhgnSY_4.mp4       43           0.058240\n",
            "8  applauding    yt-A70byjNkwdA_4.mp4        0           0.026100\n",
            "9  applauding   yt-E14-2TmbCD8_12.mp4        1           0.539783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTsOB6_wfD6-"
      },
      "source": [
        "TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhKjMSWJfDaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a319fd9a-289c-4bfa-fbe2-902c3f8579e9"
      },
      "source": [
        "# %%\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import numpy as np\n",
        "path_prefix = Path().parent.absolute()\n",
        "dict_path = path_prefix / '/content/drive/MyDrive/accuracies_per_category.pkl'\n",
        "# Load from file\n",
        "f = open(dict_path, 'rb')\n",
        "accuracies_per_category = pickle.load(f)\n",
        "\n",
        "#%%\n",
        "l_categories = categories\n",
        "\n",
        "category_name = 'aiming'\n",
        "video_fname = 'yt-2yYb3iQCivw_130.mp4'\n",
        "\n",
        "per_frame_accuracies = np.array(accuracies_per_category[category_name][video_fname])\n",
        "\n",
        "print(f'\\t{video_fname} : Max/Min accuracy at frame:' \\\n",
        "f' {np.argmax(per_frame_accuracies)}/{np.argmin(per_frame_accuracies)}' \\\n",
        "f' with value: {per_frame_accuracies[np.argmax(per_frame_accuracies)]}' \\\n",
        "f' / {per_frame_accuracies[np.argmin(per_frame_accuracies)]}')\n",
        "# %%"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tyt-2yYb3iQCivw_130.mp4 : Max/Min accuracy at frame: 41/83 with value: [0.4076968] / [0.02076938]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3R4iqcP8aSM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}